{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.bilibili.com/pgc/view/web/season?season_id=33378'\n",
    "res = requests.get(url, headers={'User-Agent':'Chrome/87.0.4280.88'})\n",
    "\n",
    "with open('tmp_playlist.json', 'w', encoding='utf8') as f:\n",
    "    f.write(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tmp_playlist.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "assert data['code'] == 0\n",
    "assert data['message'] == 'success'\n",
    "\n",
    "videos = []\n",
    "\n",
    "for ep in data['result']['episodes']:\n",
    "    x = {}\n",
    "    videos.append(x)\n",
    "\n",
    "    x['playId'] = 'ep' + str(ep['id'])\n",
    "    x['tvid'] = int(ep['title'])\n",
    "    x['title'] = ep['long_title']\n",
    "\n",
    "len(videos)\n",
    "videos[3]\n",
    "\n",
    "with open('tvlist.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(videos, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract wiki by 海外版id\n",
    "\n",
    "# zh.wikipedia.org/wiki/名偵探柯南動畫集數列表\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from itertools import islice\n",
    "import re\n",
    "\n",
    "s = BeautifulSoup(open('wiki-zh.html', 'r', encoding='utf8'))\n",
    "\n",
    "def normalize(s:str):\n",
    "    s = re.sub(r'\\[\\d+?\\]', '', s)\n",
    "    s = re.sub(r'（[^（]+?特别版）','',s)\n",
    "    s = re.sub(r'[\\s\\r\\n“”《》！·!]','',s)\n",
    "    return s\n",
    "\n",
    "def extract(table, cols:List[int], skip_rows=2) -> List:\n",
    "    info_list = []\n",
    "    for tr in islice(table.select('tr'), skip_rows, None):\n",
    "        tds = tr.select('td')\n",
    "        info = []\n",
    "        for i in cols:\n",
    "            info.append(tds[i].text)\n",
    "        info[1] = normalize(info[1])\n",
    "        \n",
    "        # extract tvid\n",
    "        idcol = tds[1].text\n",
    "\n",
    "        # 有括号(顿号分隔)；没括号(可以转换为int)\n",
    "        m = re.findall(r'\\(([^\\(\\)]+?)\\)', idcol)\n",
    "        if len(m) > 0:\n",
    "            eps = m[0].split('、')\n",
    "            eps = [int(p) for p in eps]\n",
    "        else:\n",
    "            try: \n",
    "                eps = [int(idcol)]\n",
    "            except:\n",
    "                eps = []\n",
    "                idcol:str\n",
    "                ok = idcol.startswith('魔术快斗第') or idcol == '番外特别篇'\n",
    "                if not ok:\n",
    "                    raise\n",
    "\n",
    "        for ep in eps:\n",
    "            info_list.append([ep]+info)\n",
    "\n",
    "    return info_list\n",
    "\n",
    "table_count = 13\n",
    "\n",
    "col_list = [3] * table_count\n",
    "col_list[0] = 4\n",
    "col_list = [[0, p] for p in col_list]\n",
    "\n",
    "tables = s.select('.wikitable')\n",
    "len(tables)\n",
    "\n",
    "records = []\n",
    "for i in range(table_count):\n",
    "    x = extract(tables[i], col_list[i])\n",
    "    records += x\n",
    "\n",
    "with open('wiki-by-tvid.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(records, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "source": [
    "# compare wiki tvid and bilibili -- 用眼睛看\n",
    "result_file = 'tv-with-time.json'\n",
    "\n",
    "import json\n",
    "\n",
    "wiki2 = json.load(open('wiki-by-tvid.json', 'r', encoding='utf8'))\n",
    "bili = json.load(open('tvlist.json', 'r', encoding='utf8'))\n",
    "\n",
    "# wiki to dict\n",
    "wiki2_d = {p[0]:p for p in wiki2}\n",
    "\n",
    "for tv in bili:\n",
    "    tvid = tv['tvid']\n",
    "    title = tv['title']\n",
    "\n",
    "    wiki_title = wiki2_d[tvid][2]\n",
    "    if title != wiki_title:\n",
    "        if normalize(title) != wiki_title:\n",
    "            print(title, '--', wiki_title)\n",
    "    \n",
    "    # join the data\n",
    "    pat = r'^(\\d+)年(\\d+)月(\\d+)日$'\n",
    "    ymd = list(re.findall(pat, wiki2_d[tvid][1])[0])\n",
    "    tv['pub'] = '/'.join(ymd)\n",
    "\n",
    "json.dump(bili, open(result_file,'w',encoding='utf8'), ensure_ascii=False, indent=4)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}