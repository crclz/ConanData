{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.bilibili.com/pgc/view/web/season?season_id=33378'\n",
    "res = requests.get(url, headers={'User-Agent':'Chrome/87.0.4280.88'})\n",
    "\n",
    "with open('tmp_playlist.json', 'w', encoding='utf8') as f:\n",
    "    f.write(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tmp_playlist.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "assert data['code'] == 0\n",
    "assert data['message'] == 'success'\n",
    "\n",
    "videos = []\n",
    "\n",
    "for ep in data['result']['episodes']:\n",
    "    x = {}\n",
    "    videos.append(x)\n",
    "\n",
    "    x['playId'] = 'ep' + str(ep['id'])\n",
    "    x['tvid'] = int(ep['title'])\n",
    "    x['title'] = ep['long_title']\n",
    "    # x['pub'] = ep['pub_time']\n",
    "\n",
    "len(videos)\n",
    "videos[3]\n",
    "\n",
    "with open('tvlist.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(videos, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zh.wikipedia.org/wiki/名偵探柯南動畫集數列表\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from itertools import islice\n",
    "import re\n",
    "\n",
    "s = BeautifulSoup(open('wiki-zh.html', 'r', encoding='utf8'))\n",
    "\n",
    "def extract(table, cols:List[int], skip_rows=2) -> List:\n",
    "    info_list = []\n",
    "    for tr in islice(table.select('tr'), skip_rows, None):\n",
    "        tds = tr.select('td')\n",
    "        info = []\n",
    "        for i in cols:\n",
    "            info.append(tds[i].text)\n",
    "        info_list.append(info)\n",
    "    return info_list\n",
    "\n",
    "table_count = 13\n",
    "\n",
    "col_list = [3] * table_count\n",
    "col_list[0] = 4\n",
    "col_list = [[0, p] for p in col_list]\n",
    "\n",
    "tables = s.select('.wikitable')\n",
    "len(tables)\n",
    "\n",
    "records = []\n",
    "for i in range(table_count):\n",
    "    x = extract(tables[i], col_list[i])\n",
    "    records += x\n",
    "\n",
    "rep_pat = r'[ \\r\\n“”《》！·!]'\n",
    "\n",
    "# process records, remove mark like [2]\n",
    "for r in records:\n",
    "    r[1] = re.sub(r'\\[\\w+?\\]', '', r[1])\n",
    "    r[1] = re.sub('\\n','',r[1])\n",
    "    r[1] = re.sub(r'（[^（]+?特别版）','',r[1])\n",
    "    r[1] = re.sub(rep_pat,'',r[1])\n",
    "    r[1] = r[1].upper()\n",
    "    r[1] = re.sub(r'KUDOUSHINICHI', '工藤新一', r[1])\n",
    "\n",
    "with open('wiki-zh.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(records, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match bilibili with wiki\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# load wiki\n",
    "wiki_data = json.load(open('wiki-zh.json', 'r', encoding='utf8'))\n",
    "names = set([name for [t, name] in wiki_data])\n",
    "name_and_date = {name:t for [t, name] in wiki_data}\n",
    "assert len(wiki_data) == len(names)\n",
    "\n",
    "# load bilibili\n",
    "tvlist = json.load(open('tvlist.json', 'r', encoding='utf8'))\n",
    "\n",
    "# wiki to full text search\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "    \n",
    "def closest(s: str):\n",
    "    max_score = -1\n",
    "    s2 = None\n",
    "\n",
    "    for name in names:\n",
    "        score = similar(s, name)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            s2 = name\n",
    "    return s2\n",
    "\n",
    "not_match = 0\n",
    "\n",
    "# load manual ref list\n",
    "manual_ref = dict()\n",
    "with open('manual-ref.txt', 'r', encoding='utf8') as f:\n",
    "    lines = f.read().splitlines(keepends=False)\n",
    "for line in lines:\n",
    "    ss = line.split(' -- ')\n",
    "    assert len(ss) == 2\n",
    "    manual_ref[ss[0]] = ss[1]\n",
    "\n",
    "for tv in tvlist:\n",
    "    title = tv['title']\n",
    "\n",
    "    # normalize title\n",
    "    title = re.sub(rep_pat, '', title)\n",
    "    title = title.upper()\n",
    "\n",
    "    if title not in names:\n",
    "        if False:\n",
    "            not_match += 1\n",
    "            t = closest(title)\n",
    "            print(title, '--', t)\n",
    "        # use manual ref\n",
    "        title = manual_ref[title]\n",
    "        assert title in names\n",
    "    \n",
    "    tv['wikiPub'] = name_and_date[title]\n",
    "\n",
    "with open('tv-with-time.json','w', encoding='utf8') as f:\n",
    "    json.dump(tvlist, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "dtfmt = '%Y年%m月%d日'\n",
    "\n",
    "# check date\n",
    "for i in range(len(tvlist)):\n",
    "    tv = tvlist[i]\n",
    "\n",
    "    tv['wikiPub'] = datetime.strptime(tv['wikiPub'], dtfmt)\n",
    "\n",
    "for i in range(len(tvlist)-1):\n",
    "    tv1 = tvlist[i]\n",
    "    tv2 = tvlist[i+1]\n",
    "\n",
    "    if tv1['wikiPub'] > tv2['wikiPub']:\n",
    "        print(tv1, tv2)\n",
    "# if no output, then ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}